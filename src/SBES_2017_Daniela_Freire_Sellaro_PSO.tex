\documentclass[sigconf]{acmart}


\usepackage{booktabs} % For formal tables
\usepackage{algorithm,algpseudocode}
\usepackage{blindtext, graphicx}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{epsfig}
%\usepackage[numbers]{natbib}
\usepackage{setspace}
\usepackage{multirow}
\usepackage[brazil]{babel}

% Pacotes de algoritmo
% ---
%\usepackage{algpseudocode,algorithm}
%\usepackage[portuguese, ruled, linesnumbered]{algorithm2e}
%\usepackage[portuguese,ruled,lined]{algorithm2e}
% --- 

% Copyright
%\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}

\hyphenation{re-pre-sen-ta}
\hyphenation{ex-pe-ri-men-to}
\hyphenation{ins-tru-ções}
\hyphenation{pa-ra-le-lis-mo}
\hyphenation{mo-de-la-gem}
\hyphenation{me-lhor}
\hyphenation{di-fe-ren-tes}
\hyphenation{e-xe-cu-ção}
\hyphenation{mo-ni-to-ra-men-to}

% Configurações do pacote algpseudocode
% 
%% Declaracoes em Português
%\algrenewcommand\algorithmicend{\textbf{fim}}
%\algrenewcommand\algorithmicdo{\textbf{faça}}
%\algrenewcommand\algorithmicwhile{\textbf{enquanto}}
%\algrenewcommand\algorithmicfor{\textbf{para}}
%\algrenewcommand\algorithmicif{\textbf{se}}
%\algrenewcommand\algorithmicthen{\textbf{então}}
%\algrenewcommand\algorithmicelse{\textbf{senão}}
%\algrenewcommand\algorithmicreturn{\textbf{devolve}}
%\algrenewcommand\algorithmicfunction{\textbf{função}}
%
%% Rearranja os finais de cada estrutura
%\algrenewtext{EndWhile}{\algorithmicend\ \algorithmicwhile}
%\algrenewtext{EndFor}{\algorithmicend\ \algorithmicfor}
%\algrenewtext{EndIf}{\algorithmicend\ \algorithmicif}
%\algrenewtext{EndFunction}{\algorithmicend\ \algorithmicfunction}
%%
%----

% DOI
%\acmDOI{10.475/123_4}

% ISBN
%\acmISBN{123-4567-24-567/08/06}

%Conference
\copyrightyear{2017} 
\acmYear{2017} 
\setcopyright{acmcopyright}
\acmConference{SBES'17}{September 20--22, 2017}{Fortaleza, CE, Brazil}\acmPrice{15.00}\acmDOI{10.1145/3131151.3131191}
\acmISBN{978-1-4503-5326-7/17/09}


\begin{document}
	
	\title{Task Scheduling Optimization on Enterprise Application Integration Platforms Based on the Meta-heuristic Particle Swarm Optimization}
	
	%\titlenote{Produces the permission block, and
	%  copyright information}
	%\subtitle{Extended Abstract}
	%\subtitlenote{The full version of the author's guide is available as
	%  \texttt{acmart.pdf} document}
	
	
	\author{Daniela F. Sellaro}
	%\authornote{Dr.~Trovato insisted his name be first.}
	%\orcid{1234-5678-9012}
	\affiliation{%
		\institution{Unijuí University}
		%{Universidade Regional do Noroeste do Estado do Rio Grande do Sul}
		%\streetaddress{P.O. Box 1212}
		\city{Ijuí} 
		\state{RS} 
		%\postcode{43017-6221}
	}
	\email{dsellaro@unijui.edu.br}
	
	\author{Rafael Z. Frantz}
	%\authornote{The secretary disavows any knowledge of this author's actions.}
	\affiliation{%
		\institution{Unijuí University}
		%{Universidade Regional do Noroeste do Estado do Rio Grande do Sul}
		%\streetaddress{P.O. Box 1212}
		\city{Ijuí} 
		\state{RS} 
		%\postcode{43017-6221}
	}
	\email{rzfrantz@unijui.edu.br}
	
	\author{Inma Hernández}
	\affiliation{%
		\institution{University of Seville}
		%  \streetaddress{P.O. Box 5000}}
		%	\city{Sevilha} 
		\coutry{Espanha} 
	}
	\email{inmahernandez@us.es}
	
	\author{Fabricia Roos-Frantz}
	%\authornote{The secretary disavows any knowledge of this author's actions.}
	\affiliation{%
		\institution{Unijuí University}
		%{Universidade Regional do Noroeste do Estado do Rio Grande do Sul}
		%\streetaddress{P.O. Box 1212}
		\city{Ijuí} 
		\state{RS} 
		%\postcode{43017-6221}
	}
	\email{frfrantz@unijui.edu.br}
	
	\author{Sandro Sawicki}
	\affiliation{%
		\institution{Unijuí University}
		%{Universidade Regional do Noroeste do Estado do Rio Grande do Sul}
		%\streetaddress{P.O. Box 1212}
		\city{Ijuí} 
		\state{RS} 
		%\postcode{43017-6221}
	}
	\email{sawicki@unijui.edu.br}
	
	
	% The default list of authors is too long for headers}
	\renewcommand{\shortauthors}{Daniela F. Sellaro et al.}
	\renewcommand{\shorttitle}{Task Scheduling Optimization on EAI Platforms Based on the Meta-heuristic PSO}
	%\maketitle	
	%----
	% CONFIGURAÇÕES DE PACOTES
	% --- 
	
	% ---
	
	%\selectlanguage{brazilian}
	
	\begin{abstract}
		%-- Context	
		Companies seek technological alternatives that provide competitiveness for their business processes. Among these alternatives, there are integration platforms that allow you to connect applications to your software ecosystems. These ecosystems are often composed of local applications and cloud computing services, such as SaaS and PaaS, and still, interact with social media.
		Integration platforms are specialized software that allows you to design, execute and monitor integration solutions, which connect functionality and data from different applications. Integration platforms typically provide a specific domain language, development toolkit, runtime engine, and monitoring tool.
		% - What is the problem?
		The efficiency of the engine in scheduling and performing integration tasks has a direct impact on the performance of a solution and this is one of the challenges faced by integration platforms.
		% - Why is it a problem?
		Our literature review has identified that integration engines adopt task scheduling algorithms based on the \ textit {First-In-First-Out} discipline, which may be inefficient. Therefore, it is appropriate to seek a task scheduling algorithm that optimizes engine performance, providing a positive impact on the performance of the integration solution in different scenarios.
		% - Our solution
		This article proposes an algorithm for task scheduling based on the meta-heuristic optimization technique, which assigns the tasks to the computational resources, considering the waiting time in the queue of ready tasks and the computational complexity of Each task in order to optimize the performance of the integration solution.
		
	\end{abstract} 
	%
	% The code below should be generated by the tool at
	% http://dl.acm.org/ccs.cfm
	% Please copy and paste the code instead of the example below. 
	%
	\begin{CCSXML}
		<ccs2012>
		<concept>
		<concept_id>10011007.10010940.10011003.10011002</concept_id>
		<concept_desc>Software and its engineering~Software performance</concept_desc>
		<concept_significance>500</concept_significance>
		</concept>
		<concept>
		<concept_id>10011007.10010940.10010971.10011120.10003100</concept_id>
		<concept_desc>Software and its engineering~Cloud computing</concept_desc>
		<concept_significance>300</concept_significance>
		</concept>
		<concept>
		<concept_id>10011007.10010940.10010992.10010993.10010995</concept_id>
		<concept_desc>Software and its engineering~Real-time schedulability</concept_desc>
		<concept_significance>100</concept_significance>
		</concept>
		</ccs2012>
	\end{CCSXML}
	
	\ccsdesc[500]{Software and its engineering~Software performance}
	\ccsdesc[300]{Software and its engineering~Cloud computing}
	\ccsdesc[100]{Software and its engineering~Real-time schedulability}
	\keywords{Integrating Enterprise Applications, Optimization, Cloud computing, Runtime System, Task Scheduling Algorithm.}
	
	
	%\selectlanguage{english}
	
	% 
	%\keywords{Enterprise Application Integration; Optimization; Cloud computing; Runtime System; Task scheduling algorithm}
	%
	%\selectlanguage{english}
	%
	%\maketitle
	
	%\begin{CCSXML}
	%	<ccs2012>
	%	<concept>
	%	<concept_id>10010520.10010553.10010562</concept_id>
	%	<concept_desc>Computer systems organization~Embedded systems</concept_desc>
	%	<concept_significance>500</concept_significance>
	%	</concept>
	%	<concept>
	%	<concept_id>10010520.10010575.10010755</concept_id>
	%	<concept_desc>Computer systems organization~Redundancy</concept_desc>
	%	<concept_significance>300</concept_significance>
	%	</concept>
	%	<concept>
	%	<concept_id>10010520.10010553.10010554</concept_id>
	%	<concept_desc>Computer systems organization~Robotics</concept_desc>
	%	<concept_significance>100</concept_significance>
	%	</concept>
	%	<concept>
	%	<concept_id>10003033.10003083.10003095</concept_id>
	%	<concept_desc>Networks~Network reliability</concept_desc>
	%	<concept_significance>100</concept_significance>
	%	</concept>
	%	</ccs2012>  
	%\end{CCSXML}
	%
	%\ccsdesc[500]{Computer systems organization~Embedded systems}
	%\ccsdesc[300]{Computer systems organization~Redundancy}
	%\ccsdesc{Computer systems organization~Robotics}
	%\ccsdesc[100]{Networks~Network reliability}
	
	%
	% End generated code
	%
	
	%\keywords{Integração de Aplicações Empresariais, Otimização; Computação em nuvem, Motor de execução, Algoritmo de agendamento de tarefas}
	
	\maketitle	
 
 %==============================================================================
 \section{Introdu\c{c}\~{a}o}
 \label{sec:introducao}
 %==============================================================================
 
 %Inicie aqui o texto da sua introdução. As referências devem ser feitas utilizando o codigo a seguir~\cite{Ermagan08}
 
 %Uma figura é inserida no texto da seguinte forma: A Figura~\ref{fig:sample-eai-solution} representa ...
 
 %\begin{figure}
 %    \includegraphics[scale=0.7]{./figs/sample-solution.eps}
 %   \caption{Sample EAI solutions.}
 %    \label{fig:sample-eai-solution}
 %\end{figure}
 %-- Context
 %A Integração de Aplicações Empresariais (EAI) é o campo de estudo que proporciona metodologias, técnicas e ferramentas para a 
 \noindent 
 %--Context
 As empresas possuem um ecossistema de software composto por diversas aplicações que geralmente são desenvolvidas internamente ou adquiridas de terceiros. O avanço das tecnologias de desenvolvimento de aplicações e a incorporação de serviços de software disponíveis na internet têm deixado os ecossistemas de software ainda mais heterogêneos. Os processos de negócio de uma empresa precisam ser suportados por um conjunto de aplicações e serviços de software que integram seu ecossistema, porém, frequentemente, tais aplicações e serviços não estão preparados para trabalhar de forma conjunta. A Integração de Aplicações Empresariais (EAI) é o campo de estudo que oferece metodologias, técnicas e ferramentas para que os processos de negócio funcionem de forma sincronizada, promovendo repostas rápidas e confiáveis.  
 
 %--Problem
 As plataformas de integração são softwares especializados que permitem projetar, executar e monitorar soluções de integração, as quais conectam funcionalidades e dados de diferentes aplicações. Uma solução de integração implementa um fluxo de integração composto por distintas tarefas atômicas que são executadas ao longo desse fluxo. Gregor Hophe e Bobby Woolf~\cite{hohpe2004} documentaram um conjunto de padrões de integração que tem inspirado o desenvolvimento de plataformas de integração de código aberto e que por sua vez organizam o fluxo de integração seguindo uma arquitetura Pipes\&Filters~\cite{alexander1977}. 
 %Dentre essas plataformas, destacam-se Camel~\cite{isen2010}, Spring~\cite{fisher2012}, Mule~\cite{dossot2014}, Guaraná~\cite{frantz2016}, Jitterbit~\cite{russell2012} e
 % WSO2 ESB~\cite{indrasiri2016}. 
 Usualmente, essas plataformas fornecem uma linguagem de domínio específico, um kit de ferramentas de desenvolvimento, um motor de execução e uma ferramenta de monitoramento. A linguagem de domínio específico possibilita a descrição de modelos conceituais para soluções de integração. O kit de desenvolvimento é um conjunto de ferramentas de software que permite a implementação de soluções, ou seja, transforma uma solução conceitual em código executável. O motor proporciona todo o suporte necessário à execução das soluções de integração. A ferramenta de monitoramento é utilizada para detectar erros que possam ocorrer durante a execução de soluções de integração. O motor é o responsável pela execução das soluções de integração~\cite{frantz2016}. 
 
 As tarefas da solução de integração são executadas por meio de recursos computacionais presentes no motor de execução, dentre os quais estão as \emph{threads} de execução. Neste contexto, as \emph{threads} s\~{a}o usadas para proporcionar que as tarefas sejam executadas de forma simultânea, por meio da programação \emph{multithreads}~\cite{dietel2009,tanebaum2009}. Nesse tipo de programação, a criação de \emph{threads} pode impactar o desempenho da execução de uma solução de integração.
 
 %-- Why it is a problem
 Um algoritmo de agendamento de tarefas inadequado aumenta o tempo de execução, impactando o desempenho da solução de integração. A abordagem mais comum é a contratação de mais recursos computacionais, porém essa alternativa é financeiramente onerosa e nem sempre viável. Nossa revisão da literatura identificou que os motores de integração adotam como política de agendamento de tarefas as políticas de prioridade e a \textit{First-In-First-Out} (FIFO). Há propostas de algoritmos de agendamento de tarefas para máquina virtuais em sistemas distribuídos~\cite{rodriguez2014,al2015}, porém não foram identificadas propostas que foquem na otimização de desempenho de motores de execução de plataformas de integração de sistemas. 
 
 O agendamento de fluxo de trabalho tem sido amplamente estudado ao longo dos anos, nos quais os algoritmos se concentram na geração de soluções aproximadas ou quase ótimas, por se tratar de um problema não polinomial difícil~\cite{sousa2004}. Pandey et al.~\cite{pandey2010} propõem um algoritmo baseado em PSO para minimizar o custo de execução de um único fluxo de trabalho enquanto equilibra a carga da tarefa nos recursos disponíveis. Wu et al.~\cite{wu2010} usam PSO para produzir um agendamento quase ideal, se preocupando em minimizar custo e tempo, mas assume que um conjunto limitado de recursos, sem levar em conta a elasticidade proporcionada com a computação em das nuvens. O algoritmo de Byun et al.~\cite{byun2011} estima o número ótimo de recursos que precisam ser alocados para que o custo de execução de um fluxo de trabalho seja minimizado. Sua abordagem aproveita a elasticidade dos recursos da nuvem, mas não considera a natureza heterogênea dos recursos computacionais.
 
 A contribuição deste trabalho é a aplicação da meta-heurística \textit{Particle Swarm Optimization} (PSO) para o contexto dos motores de execução, nos quais as políticas de agendamento adotadas, não consideram o tempo de espera na fila de tarefas prontas, nem a complexidade computacional das tarefas. PSO é fácil de implementar e existirem poucos parâmetros para serem ajustado, adequando-se ao problema de encontrar melhor agendamento das tarefas. Classifica-se como uma pesquisa exploratória, a medida que busca um método mais eficiente do que os existentes, na resolução do problema. Um resumo com ideias iniciais para esse trabalho foi apresentado em um seminário de pesquisa~\cite{sellaro2017}, e o presente artigo as discute de forma mais ampla e completa  a proposta de um algoritmo que busca o mapeamento ótimo das tarefas para os pools de \emph{threads}.
 
 %-- Solution
 O resto deste artigo está organizado como segue. A Seção 2 apresenta a formulação do problema. A Seção 3 descreve sucintamente a técnica PSO. A Seção 4 expõe a abordagem proposta. E a Seção 5 apresenta nossas conclusões e perspectivas de trabalhos futuros. 
 %	\input{./src/Problema}
 %==============================================================================
 \section{Formula\c{c}\~{a}o do Problema}
 \label{sec:formulacao_problema}
 %==============================================================================
 Numa solução de integração, baseada no estilo arquitetural \emph{Pipes\&Filters}~\cite{alexander1977}, os \textit{pipes} são representados por canais de mensagens e os \textit{filters} por tarefas atômicas que implementam um padrão de integração concreto e processam dados encapsulados em mensagens.
 % A Figura~\ref{fig:pipes-filters} representa esse estilo arquitetural.
 %\begin{figure}[htb]
 %	\centering
 %	\includegraphics[width=\linewidth]{./figs/pipes_filters.png}
 %	\caption{Estilo arquitetural \emph{Pipes\&Filters}}
 %	\label{fig:pipes-filters}
 %\end{figure}
 A Figura~\ref{fig:sample-cafe} mostra um exemplo mostra o modelo conceitual de uma solução de integração para o problema Café, introduzido por Gregor Hohpe~\cite{hohpe2005} modelado com Guaraná~\cite{frantz2016}.
 \begin{figure}[htb]
 	\centering
 	\includegraphics[scale=0.25]{./figs/cafe-guarana.png}
 	%\includegraphics[width=\linewidth]{./figs/cafe-guarana.png}
 	\caption{Solução de integração Café}
 	%Fonte: \cite{fisher2012spring}
 	\label{fig:sample-cafe}
 \end{figure}
 O modelo conceitual pode ser representado como fluxos de trabalho modelados como Grafos Direcionados Acíclicos, definidos por W(T,E), onde $T = \{t_1,t_2,..t_n\}$ é o conjunto de tarefas e $E$ é o conjunto de arestas direcionadas. Uma aresta $e_{ij}$ da forma $({t_i},{t_j})$ existe, se houver uma dependência de dados entre $t_i$ e $t_j$, onde $t_i$ é tarefa pai de $t_j$ e $t_j$ é tarefa filha de $t_i$. Logo, uma tarefa filha não pode ser executada até que todas as suas tarefas pai estejam concluídas. 
 %A Figura~\ref{fig:workflow} mostra fluxos de trabalho da solução de integração Café, onde cada vértice representa uma tarefa e cada aresta possui um peso, que representa o tempo de espera da mensagem na fila de tarefas prontas.
 %\begin{figure}[htb]
 %	\centering
 %	\includegraphics[scale=0.14]{./figs/workflow.png}
 %	%\includegraphics[width=\linewidth]{./figs/workflow.png}
 %	\caption{Workflow da solução de integração Café.}
 %	\label{fig:workflow}
 %\end{figure}
 Considera-se que o motor de execução oferece uma variedade de recursos computacionais para execução das tarefas da solução de integração. Essa variedade de recursos é definida por \emph{pool} de \emph{threads}, com diferentes números de \emph{threads}, onde uma \emph{thread} é a unidade básica de processamento. Assim, assume-se que um motor de execução pode ter mais de um \emph{pool} de \emph{threads} e que o número de \emph{threads} em cada um pode ser diferente, ou seja, um \emph{pool} com uma quantidade \textit{x} \emph{threads} e outro com uma quantidade \textit{y}. Considera-se ainda, que um motor de execução tem uma quantidade limitada de recursos computacionais ${\delta _r}$, sendo um recurso computacional $Pool$, um \emph{pool} de \emph{threads} que tem um tipo $Pool _i$, uma capacidade de processamento $PPool_j$. O tipo diferencia os \emph{pools}, a capacidade de processamento é a quantidade de \emph{threads} do \emph{pool}. A capacidade de memória não é tratada; assume-se que é suficiente para executar as tarefas do fluxo de trabalho. Assume-se que para cada tipo de recurso, a capacidade de processamento é definida em termos de instruções por ciclo (IPC), que pode ser estimada~\cite{abraham2016runtime}. Esta informação é usada no algoritmo, para calcular o tempo de execução de uma tarefa em um determinado \emph{pool} de \emph{threads} $Pool$. A variação do desempenho pode ser modelada pelo ajuste da capacidade do $Pool$ e introduzindo uma degradação de desempenho $deg_{Pool_{j}}$ ~\cite{rodriguez2014}. 
 O tempo de execução $TE_{{t_i}}^{Poo{l_j}}$ da tarefa $t_i$ em um $Pool$ de tipo $Pool_j$ é estimado pelo tamanho $Ta{m_{{t_i}}}$ da tarefa em instruções por ciclo (IPC), calculado pela Equação~\ref{equa:tempo-execucao}. 
 \begin{equation}
 TE_{{t_i}}^{Pool_{j}} = Ta{m_{{t_i}}}/({P_{Pool_{j}}}*(1 - {\deg _{Pool_{j}}}))
 \label{equa:tempo-execucao}
 \end{equation}
 %onde:
 %
 %$Ta{m_{{t_i}}}$ = tamanho da tarefa
 %
 %$ {P_{Poo{l_j}}} $ = capacidade de processamento do \emph{pool} de threads
 %
 %$ {\deg _{Poo{l_j}}} $ = degradação de desempenho
 O tempo médio de espera na fila de tarefas $TF{i_{e_{ij}}}$ é definido como o tempo para transferir dados entre uma tarefa pai $t_i$ e sua tarefa filha $t_j$ e assume-se que ele pode ser monitorado e medido.  
 
 Finalmente, o tempo total de processamento $TP_{{t_i}}^{Poo{l_j}}$ de uma tarefa em um $Pool$ é calculado na Equação~\ref{equa:tempo-processamento}, onde k é o número de arestas, $t_i$ é uma tarefa pai e $s_k$ representa o tempo gasto pelo motor na troca de \emph{pool} de threads, de maneira que $s_k$ = 0, quando $t_i$ e $t_j$ são processadas no mesmo \emph{pool} e  $s_k$ = 1, caso contrário.
 \begin{equation}
 TP_{{t_i}}^{Poo{l_j}} = TE_{{t_i}}^{Poo{l_j}} + (\sum\limits_1^k {T{F_{ij}} + {s_k}} )
 \label{equa:tempo-processamento}
 \end{equation}
 %onde:
 %
 %$ TE_{{t_i}}^{Poo{l_j}} $ = tempo de execução da tarefa em um determinado \emph{pool} de threads.
 %
 %$TF{i_{e_ij}}$  = tempo de espera na fila de tarefas, ou seja, tempo que para transferir dados entre uma tarefa e sua tarefa filha. 
 %
 %$ {s_k} $ = tempo gasto na troca de \emph{pool} de threads.
 %
 %$ k $ =  número de arestas em que uma tarefa é uma tarefa pai. 
 O objetivo é encontrar um agendamento de tarefas que possibilite executar as tarefas da solução de integração em \emph{pools} de \emph{threads} do motor de execução, minimizando o tempo total de execução e sem aumentar a quantidade de recursos computacionais. O agendamento de tarefas é definido por $A= (R, M, TR, TTE)$, sendo $R$ um conjunto de recursos; $M$ o mapeamento de tarefas em recursos, $TR$, $TR=\arrowvert R\arrowvert =n$, o total de recursos, $TTE$ o tempo total de execução. Um exemplo é mostrado na Figura~\ref{fig:grafico-mapeamento}, representando o agendamento para o fluxo de trabalho da Figura~\ref{fig:workflow}, em que cada uma das quatro tarefas é mapeada para ser executada por um dos três recursos disponíveis, e onde as tarefas pais são executadas antes das sua tarefas filhas, mantendo assim a dependência dos dados.
 \begin{figure}[htb]
 	\centering
 	\includegraphics[scale=0.2]{./figs/grafico-mapeamento.png}
 	%\includegraphics[width=\linewidth]{./figs/grafico-mapeamento.png}
 	\caption{Agendamento para o workflow do Café.}
 	\label{fig:grafico-mapeamento}
 \end{figure}
 $R = \{ {r_1},{r_2},...,{r_n}\}$  é o conjunto de recursos (\emph{pools} de \emph{threads}) do motor de execução, onde cada recurso $r_i$ tem associado a ele um $Pool$ do tipo $Pool_i$, um tempo de início estimado para alocação do recurso estimado ${TIni_{r_i}}$. e um tempo de finalização estimado ${TFim_{r_i}}$. M representa um mapeamento para cada uma das tarefas do fluxo de trabalho e é constituído por tuplas $ m_{{t_i}}^{{r_j}} = ({t_i},{r_j},TIn{i_{{t_i}}},TFi{n_{{t_i}}})$, significando que a tarefa $t_i$ será executada pelo recurso $r_j$, com o início da execução agendado para $ TIn{i_{{t_i}}} $ e previsão de término em $ TFi{n_{{t_i}}} $. A Equação~\ref{equa:tempo-total-execução} mostra como o tempo total de execução $ TTE $ é calculado:
 \begin{equation}
 TTE = \max \{ TFi{m_{{t_i}}}:{t_i} \in T\} 
 \label{equa:tempo-total-execução}
 \end{equation}
 Assim, o problema pode ser formulado como: \textit{encontrar um agendamento $A$ com o menor tempo total de execução $TTE$ da solução de integração, sem exceder um valor pré-definido para o total de recursos $TR$}. Essa formulação é representada pela Equação~\ref{equa:problema}:
 \begin{equation}
 Minimize {TTE} 
 \label{equa:problema}
 \end{equation}
 \begin{center}
 	sujeito a ${TR \le {\delta _r}} $
 \end{center}
% 	\input{./src/PSO}
%==============================================================================
\section{Particle Swarm Optimization}
\label{sec:PSO}
%==============================================================================
\textit{Particle Swarm Optimization} (PSO) foi introduzido por Kennedy e Eberhart em 1995~\cite{eberhart1995}, e foi inspirado no comportamento social de organismos biológicos, mais especificamente na habilidade de algumas espécies de animais de trabalhar em conjunto para localizar boas regiões com fontes de alimento, assim como ocorre em cardumes e em bandos de pássaros~\cite{bratton2007}. Em outras palavras, é baseado em um enxame de partículas (\emph{Particle Swarm}) que se movem pelo espaço e se comunicam para determinar uma direção de busca ideal. O PSO tem melhor desempenho computacional para este tipo de problema de otimização de funções não-lineares de alta dimensionalidade com variáveis contínuas, do que outros algoritmos~\cite{eberhart1995,bratton2007,alrashidi2009} e tem menos parâmetros para ajustar, facilitando sua implementação. O PSO vem sendo utilizado com sucesso na solução de problemas da ciência e da engenharia devido à sua simplicidade, eficácia e robustez~\cite{fukuyama1999, ourique2002, sousa2004,van2006,engelbrecht2007, alrashidi2009,rodriguez2014,al2015}. Apresenta como desvantagens, a necessidade de informação do tomador de decisão, parâmetros difíceis de ajustar, e ainda incapacidade de alcançar a Frente de Pareto, principalmente em problemas com multimodalidade, aqueles com múltiplas soluções ótimas, onde algumas podem ser melhores soluções globais e outras melhores soluções locais~\cite{figueiredo2013}, porém adapta-se ao problema abordado.

Cada partícula $ i $ do enxame $ S $ é representada por sua posição e sua velocidade. A posição é um vetor de $ n $ dimensões, cujos componentes representam os parâmetros da função objetivo. As partículas controlam a sua melhor posição $ pbest $ e a melhor posição global $ gbest $, a melhor solução conhecida dentro de sua vizinhança.

Inicialmente, as partículas do enxame possuem posições aleatórias no espaço de busca, obedecendo uma distribuição de probabilidade uniforme. Posteriormente, a posição $ {x_i}\left( t \right) $ de cada partícula $ i $ na iteração $ t $ é modificada por uma velocidade estocástica $ {v_i}\left( t \right) $ que depende da distância que a partícula está da sua melhor solução conhecida e da distância para a melhor solução conhecida dentro de sua vizinhança. Cada partícula $i \in S$ se movimenta em cada dimensão $j \in \left\{ {1,2,..n} \right\}$ do espaço de busca em um instante discreto de tempo $ t $, segundo as Equações~\ref{equa:pso1} e~\ref{equa:pso2}:
\begin{equation}
{\overrightarrow x _i}\left( {t + 1} \right) = {\overrightarrow x _{_i}}\left( t \right) + {\overrightarrow v _i}\left( t \right)
\label{equa:pso1}
\end{equation}
%
\begin{equation}
{\overrightarrow v _i}\left( {t + 1} \right) = w{\overrightarrow v _i}\left( t \right) + {c_1}{r_1}\left( {\overrightarrow x _i^*\left( t \right) - {{\overrightarrow x }_{_i}}\left( t \right)} \right) + {c_2}{r_2}\left( {{{\overrightarrow x }^*}\left( t \right) - {{\overrightarrow x }_{_i}}\left( t \right)} \right)
\label{equa:pso2}
\end{equation}
onde:
$ w $ = inércia

$ c _i $ = coeficiente de aceleração, $i=\left( 1,2 \right)$

$ r _i $ = número aleatório pertencente a uma distribuição de probabilidade uniforme , $i=\left( 1,2 \right)$ e ${r_i} \in \left[ {0,1} \right]$

$  \overrightarrow x _i^*\left( t \right) $ = melhor posição da partícula $ i $

$ {\overrightarrow x }^*\left( t \right) $ = posição da melhor partícula da população

${\overrightarrow x _{_i}}\left( t \right)$ = posição atual da partícula $ i $\\
Quando a vizinhança das partículas consiste no enxame inteiro, a posição ${\overrightarrow x _{_i}}\left( t \right)$ é denominada de $ gbest $. O vetor velocidade é quem orienta o processo de otimização, usando tanto o conhecimento adquirido particularmente pela partícula quanto o conhecimento adquirido pela partícula baseada na interação com sua vizinhança. O termo $ {c_1}{r_1}\left( {\overrightarrow x _i^*\left( t \right) - {{\overrightarrow x }_{_i}}\left( t \right)} \right) $ da equação de atualização da velocidade é a componente cognitiva e representa a experiência da partícula. Essa componente é a responsável pela tendência que a partícula tem de voltar para a melhor solução encontrada por ela no passado. O termo $ {c_2}{r_2}\left( {{{\overrightarrow x }^*}\left( t \right) - {{\overrightarrow x }_{_i}}\left( t \right)} \right) $, por sua vez, é conhecido como componente social da equação da velocidade, e representa o conhecimento coletivo do enxame, sendo responsável por atrair cada partícula para a melhor solução encontrada por alguma partícula de sua vizinhança. 
% 	\input{./src/Algoritmo}
%==============================================================================
\section{Algoritmo}
\label{sec:algoritmo}
%==============================================================================
A modelagem de um problema PSO é dividida em duas fases: definição do problema e definição da função aptidão. A primeira consiste em definir como o problema será codificado, ou seja, definir como a solução será representada. A segunda, em definir o quão \textit{boa} uma partícula será medida, ou seja, definir a função de aptidão.
Já para transformar o problema PSO em um algoritmo, é preciso definir a partícula e sua dimensão. Na abordagem adotada neste artigo, uma partícula representa um fluxo de trabalho e suas tarefas, e dimensão da partícula representa o número de tarefas no fluxo de trabalho. A dimensão de uma partícula serve para localizar sua posição no espaço, definindo o sistema de coordenadas. No exemplo apresentado na Figura~\ref{fig:workflow}, a dimensão da partícula é quatro, sendo sua posição especificada por um sistema com quatro coordenadas.

Uma partícula movimenta-se num espaço limitado, denomina-se alcance. Na abordagem adotada neste artigo, o alcance é determinado pelo número de \emph{pools} de \emph{threads} disponíveis para executar a tarefa. Assim, o valor de uma coordenada no sistema de coordenadas, que define o espaço de movimentação da partícula, tem um alcance de 0 até o número máximo de \emph{pools} de \emph{threads} disponíveis. A parte inteira do valor de uma coordenada na posição de uma partícula corresponde ao número de \emph{pools} de \emph{threads} e representa o recurso computacional atribuído a uma tarefa definida por essa coordenada específica. Assim, a posição da partícula corresponde a um mapeamento da tarefa em recursos. 

A Figura~\ref{fig:coordenadas} apresenta um exemplo de valores para as dez coordenadas do nosso sistema de coordenadas, no qual existem três recursos computacionais (\emph{pools} de \emph{threads} disponíveis), de forma que o valor de cada coordenada poderá variar entre 0 e 3. Há 4 tarefas para serem mapeadas, o que corresponde a dimensão 4 da partícula, portanto a posição da partícula terá 4 coordenadas. O índice da coordenada (de 1 a 4) corresponde a uma tarefa (de $t_1$ a $t_{4}$). O valor da coordenada é um número real de 0 a 3 , correspondendo ao número de recursos disponíveis para cada tarefa, com o máximo de 3 no nosso exemplo. Quando esse número inteiro é arredondado, é determinado o número de recursos disponíveis para cada tarefa. 
%Conforme o exemplo da Figura~\ref{fig:coordenadas}, a coordenada 1 da tarefa 1 tem valor igual a $1,3$ significando que para essa tarefa foi alocado 1 recurso, pois 1 é a parte inteira desse valor; a coordenada 2, corresponde a tarefa 2, tem valor de $ 2,0 $ indica que para a tarefa 2 foram alocados 2 recursos; e assim, sucessivamente até a coordenada 4.
%\begin{figure}[htb]
%\centering
%\includegraphics[scale=0.25]{./figs/coordenadas.png}
%\caption{Coordenadas da posição das partículas no espaço.}
%\label{fig:coordenadas}
%\end{figure}
A função de aptidão deve refletir os objetivos do problema de agendamento, pois ela é usada para determinar o quão boa uma determinada solução é. Nessa abordagem, ela é minimizada e seu valor será o tempo total de execução $TTE$ contido no agendamento $A$ derivado da posição da partícula. Considerando que o motor de execução é capaz de aumentar elástica e dinamicamente a quantidade de recursos, o modelo de aquisição oferecido pela computação em nuvem parece ilimitado, ou seja, não há um conjunto de recursos disponíveis que pode ser usado no algoritmo. A estratégia é definir um conjunto inicial de recursos que o algoritmo pode usar para explorar diferentes soluções e alcançar o agendamento. O tamanho desse conjunto será nossa restrição ${TR \le {\delta _r}} $, conforme a Equação~\ref{equa:problema}. Tal estratégia tem de refletir a heterogeneidade dos \emph{pools} de \emph{threads} (diferentes números de \emph{threads}) e oferecer opções suficientes de PSO, a fim de que seja produzida uma partícula adequada, ou seja, a solução. O conjunto de recursos inicial e limitado conterá os recursos que podem ser usados. Se esse conjunto é muito grande, o número de agendamento possíveis aumentará, assim como, o espaço de pesquisa explorado pelo PSO, tornando difícil para o algoritmo convergir e encontrar uma solução adequada~\cite{rodriguez2014}.

Para reduzir o tamanho do espaço de pesquisa, o qual será usado pelo PSO para encontrar um agendamento próximo do ótimo, considera-se um conjunto de recursos inicial $R_{inicial}$, composto por um $Pool$ de cada tipo, para cada tarefa em P; onde P é o conjunto que contém o número máximo de tarefas que podem ser executadas em paralelo para um dado fluxo de trabalho. O algoritmo selecionará o número e o tipo apropriados de $Pools$ para o motor de execução, dentro das opções contidas em $R_{inicial}$. Assim, reflete-se a heterogeneidade dos recursos computacionais e reduz-se o tamanho do espaço de busca, além de permitir mapear todas as tarefas que podem ser executadas em paralelo. O tamanho de $R_{inicial}$ seria igual a $\left| P \right|*n$, onde $n$ é o número de tipos de $Pools$ disponíveis, sendo ainda possível, que o PSO selecione mais de um recurso $\left| P \right|$, se necessário (a menos que $n = 1$).

O problema abordado possui a restrição  ${TR \le {\delta _r}} $, utiliza-se uma versão do PSO que incorpora uma estratégia para tratar restrições~\cite{deb2002}. Nela, sempre que duas soluções estão sendo comparadas e (\textit{i}) ambas as soluções forem viáveis, então a solução com melhor aptidão é selecionada; (\textit{ii}) se uma solução é viável e a outra não é, então a viável é selecionada; e finalmente, (\textit{iii}) se ambas as soluções são inviáveis, aquela que violar menos a restrição é selecionada. No último caso, implica que uma medida de quanto uma solução viola a restrição precisa ser encontrada. O problema define o valor de violação de restrição de uma solução $\delta_k $, a restrição pode ser atribuída a limitação de recursos que se deseja contratar na computação em nuvem ou simplesmente e a quantidade de \emph{threads} físicas das máquinas que irão ser utilizadas na execução da solução de integração. Uma solução do PSO que utilize recursos próximos de $\delta_k$ será preterida em relação a uma solução menos recursos.

O Algoritmo~\ref{algoritmo-agendamento} apresenta o pseudo-código para mapear a posição de uma partícula em um agendamento. O conjunto de recursos $R$ para serem alocados e o conjunto de mapeamentos $M$ de tarefas para recursos são inicializados sem elementos, ou seja, vazios, e tempo total de execução $TTE$ é inicializado com o valor zero. Na sequência, o algoritmo estima o tempo de execução de cada tarefa do fluxo de trabalho para todo o recurso ${r_i} \in {R_{inicial}}$. A representação é uma matriz em que as linhas representam as tarefas, as colunas representam os recursos e a entrada $ TempoExec[i,j] $ corresponde ao tempo gasto para executar a tarefa $t_i$ no recurso $r_j$, calculado conforme a Equação~\ref{equa:tempo-execucao}. O próximo passo é o cálculo ou atribuição da matriz de tempo de transferência de dados, ou tempo de espera na fila de tarefas, o qual assume-se que está sendo obtido por um procedimento, não tratado nesse trabalho, tal como por uma ferramenta de monitoramento. Essa matriz é representada como uma matriz de adjacência ponderada do workflow DAG, onde a entrada $ TempoTransfer[i, j]$ contém o tempo que leva para transferir os dados de saída da tarefa $t_i$ para a tarefa $t_j$ e esse valor é zero sempre que $i =j$ ou não há aresta direcionada conectando $t_i$ (tarefa pai) e $t_j$ (tarefa filha). 
% A Figura~\ref{fig:matrizes} exemplifica essas matrizes para o workflow apresentado na Figura~\ref{fig:workflow}.
%\begin{figure}[htb]
%	\centering
%	\includegraphics[width=\linewidth]{./figs/matrizes-h.png}
%	\caption{Matrizes Tempo de Execução e de Transferência.}
%	\label{fig:matrizes}
%\end{figure}
De posse dessas informações, o algoritmo inicia determinando a posição da partícula e construindo o agendamento. Para isso, itera para toda $ i $ do \textit{array} de posição $pos$ e atualiza $ R $ e $ M $. Primeiro, determina a tarefa e o recurso que está associado à coordenada atual e seu valor. A estratégia usada para isso é a descrita anteriormente, a qual indica que a coordenada $ i $ corresponde à tarefa $t_i$ e seu valor $pos[i]$ corresponde ao recurso $  {r_{pos[i]}} \in {R_{inicial}} $. Encontrados os componentes, $ {t_i} $ e $ {r_j} $, de uma tupla de mapeamento $ m_{{t_i}}^{{r_j}} $, o algoritmo calcula os demais, o tempo de inicio $ TIn{i_{{t_i}}} $ e tempo de finalização $TFi{n_{{t_i}}}$ da tarefa.

O valor de tempo de início $ TIn{i_{{t_i}}} $ diferencia-se em duas situações. Na primeira, a tarefa não tem tarefa pai e, portanto, pode começar a ser executada, assim que o recurso alocado para ela $r_{pos[i]}$ estiver disponível, o que ocorrerá quando o referido recurso terminar a execução que estiver em andamento. Na segunda situação, a tarefa tem um ou mais pais e, nesse caso, além de esperar que o recurso para ela alocado esteja disponível, também terá que aguardar pelo término da execução das suas tarefas pai, além do tempo de transferência dos dados.

O valor de $TFin_{t_i}$ é calculado baseado no tempo total de processamento e no tempo de início da tarefa. Para determinar o tempo de processamento $TP_{{t_i}}^{r_{pos[j]}}$, é necessário calcular o tempo de execução e o tempo de transferência. O primeiro é $TempoExec[i,pos[i]]$, enquanto o último é calculado pela soma dos valores do tempo de transferência $TempoTransf[i,filha(i)]$ para toda tarefa filha $t_{filha(i)}$ de ${t_i}$, que está mapeada para rodar em um recurso diferente de $r_{pos[i]}$. Esses dois valores são então somados para obter $TP_{{t_i}}^{r_{pos[j]}}$, como definido na Equação~\ref{equa:tempo-processamento}. Por fim, o valor de $TFin_{t_i}$ é obtido pela subtração de $TIni_{t_i}$ de $TP_{{t_i}}^{r_{pos[j]}}$.
Calculados os elementos de $ m $, adiciona-se recurso para $R$, se necessário. 
Quando o algoritmo termina de processar, cada coordenada do vetor posição, $R$ conterá todos os recursos necessários e os tempos de início e finalização. Além disso, o mapeamento completo das tarefas para os recursos estará em $M$ e cada tarefa terá um recurso atribuído a ela e o tempo estimado de início e o de término. Com essas informações o algoritmo pode calcular o $TTE$  associado a solução atual, conforme Equação~\ref{equa:tempo-processamento}. Nesse ponto, o algoritmo calculou $R$, $M$ e $TTE$ e poderá construir e apresentar o agendamento associado para essa posição da partícula.
\begin{algorithm}
	\caption{Geração de agendamento}
	\ {\textbf{Entrada:} Conjunto de fluxo de trabalho de tarefas $ T $}
	
	\ {Conjunto Inicial de recursos $ R_{inicial} $}
	
	\ {Um array  $pos[{\left| T \right|}]$ representando a posição da partícula}
	
	\ {\textbf{Saída:} Um agendamento $ A $}
	
	\begin{algorithmic}[1]
		
		\State { $ \texttt{R} = \emptyset, \texttt{M} =  \emptyset, TTE = 0 $ } \Comment {Inicializa componentes}
		\State { Calcula $ {{TempoExec[}}\left| T \right| \times \left| {{R_{inicial}}} \right|] $}
		\State { Calcula $ {{TempoTransf[}}\left| T \right| \times \left| T \right|] $}
		\For{$ i $}{0}{$\left| T \right|-1$} 
		\State {$ t_i = T[i], r_{pos[i]} = \texttt{R}_{inicial}[pos[i]]  $}
		\If {$ {t_i}$ não tem pai}
		\State {$ TIni_{t_i} = TFin_{r_{pos[i]}} $}
		\Else
		\State {$ TIni_{t_i} = (\max {\{TFin_{t_{pai}}:t_{pai}[ \in pais(t_i) \}},TFin_{r_{pos[i]}}) $}	
		\EndIf
		\State {$ exe = tempoExec \left[ i \right]\left[ {pos\left[ i \right]} \right] $}
		\For {cada filha $ t_{filha} $ de $ t_i $}
		\If {$ t_{filha}$ é mapeada para um recurso diferente de  $r_{pos[i]} $}
		\State { $ trasfer+ = TempoTransf[i][c] $}	
		\EndIf	
		\EndFor
		\State {$TP_{{t_i}}^{r_{pos[j]}} = exe + transf$}
		\State {$ TFin_{t_i} = TP_{{t_i}}^{r_{pos[j]}} - TIni_{t_i}  $}
		\State {$ m_{{t_i}}^{{r_{pos[j]}}} = (t_i,r_{pos[i]},TIni_{t_i},TFin_{t_i})  $}
		\State {$ \texttt{M} = \texttt{M} \cup \{ m_{{t_i}}^{{r_{pos[i]}}}\}   $}
		\If {$ {r_{pos[i]}} \notin \texttt{R}  $}
		\State {$ \texttt{R} = \texttt{R} \cup {r_{pos[i]}}  $}
		\EndIf
		\EndFor 
		\State { Calcula $ TTE $ conforme Equação~\ref{equa:tempo-total-execução} }
		\State {$ A = (R, M, TR, TTE) $}
	\end{algorithmic}
	\label{algoritmo-agendamento}
\end{algorithm}
Finalmente, os Algoritmos~\ref{algoritmo-pso} e \ref{algoritmo-agendamento} são combinados para o agendamento próximo de ótimo. Na linha 4 do Algoritmo~\ref{algoritmo-pso}, em vez de calcular o valor de aptidão da partícula, gera-se o agendamento, conforme Algoritmo~\ref{algoritmo-agendamento}. Em seguida, usa-se o $ TTE $ como valor de aptidão nas etapas seguintes e é introduzido o mecanismo de manipulação de restrição, tal que  ${TR \le {\delta _r}} $.  
% 	\input{./src/Agradecimento}
%==============================================================================
\section{Acknowledgements}
\label{sec:Agradecimentos}
%============================================================================== 
This work was supported by the Brazilian Coordination for the Improvement of Higher Education Personnel (Capes) under grants Daniela F. Sellaro and Rafael Z. Frantz
 %	\input{./src/Conclusao}
 %==============================================================================
 \section{Conclus\~{a}o}
 \label{sec:conclusao}
 %============================================================================== 
 A eficiência dos motores de execução das plataformas de integração está diretamente relacionado com o algoritmo de agendamento das tarefas e a alocação de \emph{threads} para executá-las. Um algoritmo ineficiente leva a um aumento do tempo de execução, degradando assim o desempenho das soluções de integração. Este artigo propõe um algoritmo baseado na meta-heurística \textit{Particle Swarm Optimization} para a alocação de \emph{threads} em motores de execução baseados em filas FIFO. O algoritmo proposto atribui \emph{threads} para as tarefas considerando a complexidade computacional da tarefa e a heterogeneidade na capacidade computacional das \emph{threads}. 
 Apesar do PSO localizar de forma rápida a região das boas soluções, é lento no ajuste fino da solução, como acontece em outras técnicas, como no caso dos algoritmos genéticos.  Como trabalho futuro, pretende-se implementar esse algoritmo em um motor de execução da plataforma Guaraná para avaliar o ganho de desempenho com distintos casos de uso.	

 	
 	\begin{small}
 		\bibliographystyle{abbrvnat}
 		\bibliography{./Bibliography}
 	\end{small}
 	
 \end{document}

@article{sellaro2017,
	title={Particle Swarm Optimization para agendamento de tarefas na integra{\c{c}}{\~a}o de aplica{\c{c}}{\~o}es empresariais},
	author={Sellaro, Daniela F},
	journal={V SFCT},
	volume={14},
	year={2017}
}

@article{byun2011,
	title={Cost optimized provisioning of elastic resources for application workflows},
	author={Byun, Eun-Kyu and Kee, Yang-Suk and Kim, Jin-Soo and Maeng, Seungryoul},
	journal={Future Generation Computer Systems},
	volume={27},
	number={8},
	pages={1011--1026},
	year={2011},
	publisher={Elsevier}
}

@inproceedings{wu2010,
	title={A revised discrete particle swarm optimization for cloud workflow scheduling},
	author={Wu, Zhangjun and Ni, Zhiwei and Gu, Lichuan and Liu, Xiao},
	booktitle={Computational Intelligence and Security (CIS), 2010 International Conference on},
	pages={184--188},
	year={2010},
	organization={IEEE}
}

@inproceedings{pandey2010,
	title={A particle swarm optimization-based heuristic for scheduling workflow applications in cloud computing environments},
	author={Pandey, Suraj and Wu, Linlin and Guru, Siddeswara Mayura and Buyya, Rajkumar},
	booktitle={Advanced information networking and applications (AINA), 2010 24th IEEE international conference on},
	pages={400--407},
	year={2010},
	organization={IEEE}
}

@article{sousa2004,
	title={Particle swarm based data mining algorithms for classification tasks},
	author={Sousa, Tiago and Silva, Arlindo and Neves, Ana},
	journal={Parallel Computing},
	volume={30},
	number={5},
	pages={767--783},
	year={2004},
	publisher={Elsevier}
}

@article{frantz2016,
	title={On the design of a maintainable software development kit to implement integration solutions},
	author={Frantz, Rafael Z and Corchuelo, Rafael and Roos-Frantz, Fabricia},
	journal={Journal of Systems and Software},
	volume={111},
	pages={89--104},
	year={2016},
	publisher={Elsevier}
}

@book{dietel2009,
	title={Java how to program},
	author={Dietel, Paul},
	year={2009},
	publisher={PHI}
}

@book{tanebaum2009,
	title={Modern operating systems},
	author={Tanenbaum, Andrew},
	year={2009},
	publisher={Pearson Education, Inc.}
}

@book{isen2010,
	title={Camel in action},
	author={Ibsen, Claus \& Anstey, Jonathan},
	year={2010},
	publisher={Manning Publications Co.}
}

@book{dossot2014,
	title={Mule in action},
	author={Dossot, David and D'Emic, John and Romero, Victor},
	year={2014},
	publisher={Manning}
}

@book{fisher2012,
	title={Spring integration in action},
	author={Fisher, Mark and Partner, Jonas and Bogoevice, Marius and Fuld, Iwein},
	year={2012},
	publisher={Manning Publications Co.}
}

@book{indrasiri2016,
	title={Introduction to WSO2 ESB},
	author={Indrasiri, Kasun},
	booktitle={Beginning WSO2 ESB},
	year={2016},
	publisher={Springer}
}

@book{surhone2010,
	title={Petals Esb},
	author={Surhone, Lambert M. and Timpledon, Miriam T. and Marseken, Susan F.
	},
	year={2010},
	publisher={Betascript Publishing}
}

@book{rademakers2008,
	title={Open-source ESBs in action},
	author={Rademakers, Tijs and Dirksen, Jos},
	year={2008},
	publisher={Manning}
}
@book{jayasinghe2011,
	title={Apache Axis2 Web Services},
	author={Jayasinghe, Deepal and Azeez, Afkham},
	year={2011},
	publisher={Packt Publishing Ltd}
}
@book{russell2012,
	title={Fuse Esb},
	author={Russell, J. and Cohn, R.},
	isbn={9785510817041},
	year={2012},
	publisher={Book on Demand}
}
@book{konsek2013,
	title={Instant Apache ServiceMix How-to	},
	author={Konsek, Henryk 
	},
	year={2013},
	publisher={Packt Publishing}
}

@book{russell2012_1,
	title={Jitterbit Integration Server},
	author={Russell, J. and Cohn, R.},
	isbn={9785511924892},
	year={2012},
	publisher={Book on Demand}
}

@inproceedings{frantz2012,
	title={A software development kit to implement integration solutions},
	author={Frantz, Rafael Z. and Corchuelo, Rafael},
	booktitle={Proceedings of the 27th Annual ACM Symposium on Applied Computing},
	pages={1647--1652},
	year={2012},
	organization={ACM}
}

@article {huang2003,
	title = "A Web services-based framework for business integration solutions",
	author = "Ying Huang and Jen-Yao Chung",
	journal = "Electronic Commerce Research and Applications",
	volume = "2",
	number = "1",
	pages = "15-26",
	year = "2003",
}

@article{frantz2014,
	title={Desafios para a implanta{\c{c}}{\~a}o de solu{\c{c}}{\~o}es de integra{\c{c}}{\~a}o de aplica{\c{c}}{\~o}es empresariais em provedores de computa{\c{c}}{\~a}o em nuvem},
	author={Frantz, Rafael Z. and Sawicki, Sandro and Roos-Frantz, Fabricia and Corchuelo, Rafael and Basto-Fernandes, Vitor and Hern{\'a}ndez, Inma},
	journal={XIX Jornada de Pesquisa},
	pages={1--11},
	year={2014},
	publisher={UNIJUI}\right) 
}

@book{hohpe2004,
	title = {{Enterprise integration patterns: Designing, building, and deploying messaging solutions}},
	publisher = {Addison-Wesley Professional},
	year = {2004},
	author = {Hohpe, Gregor; Woolf, Bobby}
}

@article{hohpe2005,
	title={Your coffee shop doesn't use two-phase commit [asynchronous messaging architecture]},
	author={Hohpe, Gregor},
	journal={IEEE software},
	volume={22},
	number={2},
	pages={64--66},
	year={2005},
	publisher={IEEE}
}


@manual{fisher2012spring,
	title={Spring Integration Reference Manual, 4.3.7},
	author={Fisher, Mark and Bogoevici, Marius and others},
	year={2017},
	publisher={RELEASE}
	url={http://docs.spring.io/spring-integration/docs/2.2.0.RELEASE/reference/htmlsingle/}
}

@book{alexander1977,
	title = {{A pattern language: towns, buildings, construction}},
	publisher = {Oxford University Press},
	year = {1977},
	author = {Alexander, Christopher and Ishikawa, Sara and Silvertein, Murray}
}

@book{schildt2014,
	title={Java: the complete reference},
	author={Schildt, Herbert},
	pages={508—519},
	year={2014},
	publisher={McGraw-Hill Education Group}
}

@article{lakra2015,
	title={Multi-objective tasks scheduling algorithm for cloud computing throughput optimization},
	author={Lakra, Atul Vikas and Yadav, Dharmendra Kumar},
	journal={Procedia Computer Science},
	volume={48},
	pages={107--113},
	year={2015},
	publisher={Elsevier}
}

@inproceedings{fukuyama1999,
	title={A particle swarm optimization for reactive power and voltage control considering voltage stability},
	author={Fukuyama, Y and Nakanishi, Yosuke},
	booktitle={Proc. 11th IEEE Int. Conf. Intell. Syst. Appl. Power Syst},
	pages={117--121},
	year={1999}
}
@article{ourique2002,
	title={The use of particle swarm optimization for dynamical analysis in chemical processes},
	author={Ourique, Cl{\'a}udia O and Biscaia, Evaristo C and Pinto, Jos{\'e} Carlos},
	journal={Computers \& Chemical Engineering},
	volume={26},
	number={12},
	pages={1783--1793},
	year={2002},
	publisher={Elsevier}
}

@article{sousa2004,
	title={Particle swarm based data mining algorithms for classification tasks},
	author={Sousa, Tiago and Silva, Arlindo and Neves, Ana},
	journal={Parallel Computing},
	volume={30},
	number={5},
	pages={767--783},
	year={2004},
	publisher={Elsevier}
}

@article{rodriguez2014,
	title={Deadline based resource provisioningand scheduling algorithm for scientific workflows on clouds},
	author={Rodriguez, Maria Alejandra and Buyya, Rajkumar},
	journal={IEEE Transactions on Cloud Computing},
	volume={2},
	number={2},
	pages={222--235},
	year={2014},
	publisher={IEEE}
}

@article{al2015,
	title={Task scheduling using PSO algorithm in cloud computing environments},
	author={Al-maamari, Ali and Omara, Fatma A},
	journal={International Journal of Grid and Distributed Computing},
	volume={8},
	number={5},
	pages={245--256},
	year={2015}
}

@inproceedings{bratton2007,
	title={Defining a standard for particle swarm optimization},
	author={Bratton, Daniel and Kennedy, James},
	booktitle={Swarm Intelligence Symposium, 2007. SIS 2007. IEEE},
	pages={120--127},
	year={2007},
	organization={IEEE}
}

@article{alrashidi2009,
	title={A survey of particle swarm optimization applications in electric power systems},
	author={AlRashidi, Mohammed R and El-Hawary, Mohamed E},
	journal={IEEE Transactions on Evolutionary Computation},
	volume={13},
	number={4},
	pages={913--918},
	year={2009},
	publisher={IEEE}
}

@inproceedings{eberhart1995,
	title={Particle swarm optimization},
	author={Eberhart, Russell and Kennedy, James},
	booktitle={neural networks, 1995., Proceedings of the IEEE international joint conference on },
	pages={1942--1948},
	year={1995},
	organization={IEEE}
}

@article{figueiredo2013,
	title={Algoritmo Baseado em Enxame de Part{\'\i}culas para Otimiza{\c{c}}{\~a}o de Problemas com Muitos Objetivos},
	author={FIGUEIREDO, Elliackin Messias do Nascimento},
	year={2013},
	publisher={Universidade Federal de Pernambuco}
}

@article{alrashidi2009,
	title={A survey of particle swarm optimization applications in electric power systems},
	author={AlRashidi, Mohammed R and El-Hawary, Mohamed E},
	journal={IEEE Transactions on Evolutionary Computation},
	volume={13},
	number={4},
	pages={913--918},
	year={2009},
	publisher={IEEE}
}

@book{engelbrecht2007,
	title={Computational intelligence: an introduction},
	author={Engelbrecht, Andries P},
	year={2007},
	publisher={John Wiley \& Sons}		
}

@article{van2006,
	title={A study of particle swarm optimization particle trajectories},
	author={Van Den Bergh, Frans and Engelbrecht, Andries Petrus},
	journal={Information sciences},
	volume={176},
	number={8},
	pages={937--971},
	year={2006},
	publisher={Elsevier}
}

@masterthesis{figueiredo2013,
	title={Algoritmo Baseado em Enxame de Part{\'\i}culas para Otimiza{\c{c}}{\~a}o de Problemas com Muitos Objetivos},
	author={FIGUEIREDO, Elliackin Messias do Nascimento},
	year={2013},
	publisher={Universidade Federal de Pernambuco}
}

@book{lazinica2009,
	title={Particle swarm optimization},
	author={Lazinica, Aleksandar},
	year={2009},
	publisher={InTech Kirchengasse}
}

@patent{abraham2016runtime,
	title={Runtime capacity planning in a simultaneous multithreading (SMT) environment},
	author={Abraham, Ansu A and King, Gary M and Rosa, Daniel V and Schmidt, Donald W},
	year={2016},
	month=aug # "~16",
	publisher={Google Patents},
	note={US Patent 9,417,927}
}

@article{deb2002,
	title={A fast and elitist multiobjective genetic algorithm: NSGA-II},
	author={Deb, Kalyanmoy and Pratap, Amrit and Agarwal, Sameer and Meyarivan, TAMT},
	journal={IEEE transactions on evolutionary computation},
	volume={6},
	number={2},
	pages={182--197},
	year={2002},
	publisher={IEEE}
}
 